# LLM Router æ–‡æœ¬åˆ†ç±»é¡¹ç›®

åŸºäº HuggingFace Transformers å’Œ MLflow çš„ LLM Router æ–‡æœ¬åˆ†ç±»é¡¹ç›®ï¼Œç”¨äºè¯†åˆ«æç¤ºæ–‡æœ¬æ˜¯å¦éœ€è¦æ·±åº¦æ€è€ƒã€‚

> ğŸš€ **é¡¹ç›®å·²å‡çº§åˆ° uv ä¾èµ–ç®¡ç†** - æ›´å¿«çš„åŒ…å®‰è£…å’Œæ›´å¥½çš„ç¯å¢ƒç®¡ç†ï¼æŸ¥çœ‹ [è¿ç§»æŒ‡å—](MIGRATION_GUIDE.md) äº†è§£è¯¦æƒ…ã€‚

## é¡¹ç›®ç‰¹ç‚¹

- **å·¥ç¨‹åŒ–è®¾è®¡**: æ¨¡å—åŒ–ä»£ç ç»“æ„ï¼Œæ˜“äºæ‰©å±•å’Œç»´æŠ¤
- **MLflow é›†æˆ**: å®Œæ•´çš„å®éªŒè¿½è¸ªã€æ¨¡å‹ç®¡ç†å’Œ pipeline ç¼–æ’
- **HuggingFace Transformers**: ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œæ–‡æœ¬åˆ†ç±»
- **å¯æ‰©å±•æ€§**: æ”¯æŒä¸åŒçš„æ¨¡å‹æ¶æ„å’Œæ•°æ®é›†æ ¼å¼
- **è‡ªåŠ¨åŒ– Pipeline**: ä¸€é”®è¿è¡Œè®­ç»ƒã€è¯„ä¼°ã€é¢„æµ‹æµç¨‹

## é¡¹ç›®ç»“æ„

```
tw-mlops-demo-FastSlowRouter/
â”œâ”€â”€ data/                           # æ•°æ®é›†ç›®å½•
â”‚   â””â”€â”€ llm_router_dataset-synth/   # LLM Router æ•°æ®é›†
â”‚       â”œâ”€â”€ train.jsonl            # è®­ç»ƒé›†
â”‚       â””â”€â”€ test.jsonl             # æµ‹è¯•é›†
â”œâ”€â”€ src/                           # æºä»£ç 
â”‚   â”œâ”€â”€ data/                      # æ•°æ®å¤„ç†æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ loader.py             # æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
â”‚   â”‚   â””â”€â”€ dataset.py            # æ•°æ®é›†ç±»å®šä¹‰
â”‚   â”œâ”€â”€ models/                    # æ¨¡å‹å®šä¹‰
â”‚   â”‚   â””â”€â”€ text_classifier.py    # æ–‡æœ¬åˆ†ç±»æ¨¡å‹å°è£…
â”‚   â”œâ”€â”€ utils/                     # å·¥å…·å‡½æ•°
â”‚   â”‚   â”œâ”€â”€ device.py             # è®¾å¤‡ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ network.py            # ç½‘ç»œè¿æ¥
â”‚   â”‚   â””â”€â”€ metrics.py            # è¯„ä¼°æŒ‡æ ‡
â”‚   â”œâ”€â”€ train.py                  # è®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ evaluate.py               # è¯„ä¼°è„šæœ¬
â”‚   â””â”€â”€ predict.py                # æ¨ç†è„šæœ¬
â”œâ”€â”€ tests/                         # æµ‹è¯•ç›®å½•
â”‚   â”œâ”€â”€ conftest.py               # pytest é…ç½®
â”‚   â”œâ”€â”€ test_data_loading.py      # æ•°æ®åŠ è½½æµ‹è¯•
â”‚   â”œâ”€â”€ test_dataset.py           # æ•°æ®é›†ç±»æµ‹è¯•
â”‚   â”œâ”€â”€ test_device_utils.py      # è®¾å¤‡å·¥å…·æµ‹è¯•
â”‚   â”œâ”€â”€ test_network_utils.py     # ç½‘ç»œå·¥å…·æµ‹è¯•
â”‚   â”œâ”€â”€ test_metrics_utils.py     # è¯„ä¼°æŒ‡æ ‡æµ‹è¯•
â”‚   â””â”€â”€ test_integration.py       # é›†æˆæµ‹è¯•
â”œâ”€â”€ mlruns/                        # MLflow å®éªŒè®°å½•
â”œâ”€â”€ outputs/                       # æ¨¡å‹è¾“å‡ºç›®å½•
â”œâ”€â”€ pyproject.toml                # é¡¹ç›®é…ç½®å’Œä¾èµ–ç®¡ç†
â”œâ”€â”€ pytest.ini                   # pytest é…ç½®
â”œâ”€â”€ run.sh                        # ä¸€é”®è¿è¡Œè„šæœ¬
â””â”€â”€ README.md                     # é¡¹ç›®è¯´æ˜
```

## æ•°æ®é›†

### LLM Router æ•°æ®é›†
JSONL æ ¼å¼ï¼Œæ¯æ¡è®°å½•åŒ…å«ï¼š
- `id`: å”¯ä¸€æ ‡è¯†ç¬¦
- `prompt`: æç¤ºæ–‡æœ¬
- `label`: æ ‡ç­¾ï¼ˆ0è¡¨ç¤ºä½¿ç”¨å°æ¨¡å‹ï¼Œ1è¡¨ç¤ºä½¿ç”¨å¤§æ¨¡å‹ï¼‰

### æ•°æ®é›†ç»Ÿè®¡
- **è®­ç»ƒé›†**: `train.jsonl` (15,306 æ¡è®°å½•)
- **æµ‹è¯•é›†**: `test.jsonl` (4,922 æ¡è®°å½•)
- **æ ‡ç­¾åˆ†å¸ƒ**: å°æ¨¡å‹(0) 8,633 æ¡ï¼Œå¤§æ¨¡å‹(1) 11,595 æ¡

## å®‰è£…ä¾èµ–

### ä½¿ç”¨ uvï¼ˆæ¨èï¼‰

é¦–å…ˆå®‰è£… uvï¼š
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

ç„¶åå®‰è£…é¡¹ç›®ä¾èµ–ï¼š
```bash
uv sync
```

æˆ–è€…åˆ›å»ºå¹¶æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼š
```bash
uv venv
source .venv/bin/activate  # Linux/macOS
# æˆ–
.venv\Scripts\activate     # Windows
uv pip install -e .
```

**é‡è¦**: ç¡®ä¿æ¿€æ´»è™šæ‹Ÿç¯å¢ƒåå†è¿è¡Œ Python è„šæœ¬ï¼
```

### ä½¿ç”¨ pipï¼ˆä¼ ç»Ÿæ–¹å¼ï¼‰

```bash
pip install -r requirements.txt
```

## ä½¿ç”¨æ–¹æ³•

### 1. ä¸€é”®è¿è¡Œå®Œæ•´ Pipeline

```bash
./run.sh
```

æˆ–è€…ä½¿ç”¨ Makefileï¼š
```bash
make run
```

### 2. å•ç‹¬è¿è¡Œå„ä¸ªæ¨¡å—

#### è®­ç»ƒæ¨¡å‹
```bash
python src/train.py \
    --data_path data/llm_router_dataset-synth/train.jsonl \
    --test_path data/llm_router_dataset-synth/test.jsonl \
    --model_name huawei-noah/TinyBERT_General_4L_312D \
    --epochs 3 \
    --batch_size 128 \
    --max_length 512 \
    --device auto
```

#### è¯„ä¼°æ¨¡å‹
```bash
python src/evaluate.py \
    --data_path data/0312_training_fast_slow_thinking.jsonl \
    --model_name huawei-noah/TinyBERT_General_4L_312D \
    --device auto
```

#### å•æ¡é¢„æµ‹
```bash
python src/predict.py \
    --model_path ./outputs \
    --single \
    --prompt "ä½ çš„æç¤ºæ–‡æœ¬" \
    --device auto
```

#### æ‰¹é‡é¢„æµ‹
```bash
python src/predict.py \
    --model_path ./outputs \
    --data_path data/llm_router_dataset-synth/test.jsonl \
    --output_path predictions.jsonl \
    --device auto
```

### 3. æŸ¥çœ‹ MLflow å®éªŒè®°å½•

```bash
uv run mlflow ui
```

æˆ–è€…ä½¿ç”¨ Makefileï¼š
```bash
make mlflow-ui
```

è®¿é—® http://localhost:5000 æŸ¥çœ‹å®éªŒè®°å½•ã€å‚æ•°ã€æŒ‡æ ‡å’Œæ¨¡å‹ã€‚

### 4. ä½¿ç”¨ CLI å‘½ä»¤è¡Œå·¥å…·

é¡¹ç›®æä¾›äº† `mlops-cli` å‘½ä»¤è¡Œå·¥å…·ï¼Œç”¨äºä»åç«¯æœåŠ¡ä¸‹è½½å’Œç®¡ç†æ•°æ®é›†ã€‚

#### å®‰è£… CLI

å®‰è£…é¡¹ç›®ä¾èµ–åï¼ŒCLI ä¼šè‡ªåŠ¨å®‰è£…ï¼š

```bash
# ä½¿ç”¨ uvï¼ˆæ¨èï¼‰
uv sync

# æˆ–ä½¿ç”¨ pip
pip install -e .
```

#### é…ç½®ç¯å¢ƒå˜é‡

åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º `.env` æ–‡ä»¶ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰ï¼Œé…ç½®è®¤è¯å’Œåç«¯æœåŠ¡ä¿¡æ¯ï¼š

```bash
# Authentication Configuration
AUTH_URL=http://localhost:8081
AUTH_REALM=mlops-hub
AUTH_CLIENT_ID=mlops-cli
AUTH_CLIENT_SECRET=mlops-cli-secret

# Backend API Configuration
BACKEND_URL=http://localhost:8080
```

**æ³¨æ„**: `.env` æ–‡ä»¶å·²æ·»åŠ åˆ° `.gitignore`ï¼Œä¸ä¼šè¢«æäº¤åˆ°ç‰ˆæœ¬æ§åˆ¶ã€‚

#### CLI å‘½ä»¤

##### æŸ¥çœ‹ç‰ˆæœ¬ä¿¡æ¯

```bash
mlops-cli version
```

##### åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ•°æ®é›†

```bash
mlops-cli dataset list
```

æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨çš„æ•°æ®é›†ï¼ŒåŒ…æ‹¬ IDã€åç§°ã€æè¿°ã€æ–‡ä»¶ç±»å‹å’Œæ–‡ä»¶å¤§å°ã€‚

##### ä¸‹è½½æ•°æ®é›†

```bash
# ä¸‹è½½æœ€æ–°ç‰ˆæœ¬çš„æ•°æ®é›†ï¼ˆä¿å­˜åˆ° ./datasets ç›®å½•ï¼‰
mlops-cli dataset download <dataset_id>

# æŒ‡å®šè¾“å‡ºç›®å½•
mlops-cli dataset download <dataset_id> --output-dir ./data

# ä¸‹è½½æŒ‡å®šç‰ˆæœ¬çš„æ•°æ®é›†
mlops-cli dataset download <dataset_id> --version-id <version_id>

# ä¸‹è½½æŒ‡å®šç‰ˆæœ¬ä¸­çš„ç‰¹å®šæ–‡ä»¶
mlops-cli dataset download <dataset_id> --version-id <version_id> --file-id <file_id>
```

**ç¤ºä¾‹**:

```bash
# åˆ—å‡ºæ‰€æœ‰æ•°æ®é›†
mlops-cli dataset list

# ä¸‹è½½ ID ä¸º 1 çš„æ•°æ®é›†
mlops-cli dataset download 1

# ä¸‹è½½æ•°æ®é›†åˆ°æŒ‡å®šç›®å½•
mlops-cli dataset download 1 --output-dir ./data/llm_router_dataset-synth
```

#### é«˜çº§é€‰é¡¹

æ‰€æœ‰å‘½ä»¤éƒ½æ”¯æŒé€šè¿‡å‘½ä»¤è¡Œå‚æ•°è¦†ç›– `.env` æ–‡ä»¶ä¸­çš„é…ç½®ï¼š

```bash
# ä½¿ç”¨è‡ªå®šä¹‰åç«¯ URL
mlops-cli dataset list --backend-url http://example.com:8080

# ä½¿ç”¨è‡ªå®šä¹‰è®¤è¯é…ç½®
mlops-cli dataset download 1 \
    --keycloak-url http://keycloak.example.com:8081 \
    --realm my-realm \
    --client-id my-client \
    --client-secret my-secret
```

**æ³¨æ„**: è™½ç„¶å‚æ•°åä¸º `--keycloak-url`ï¼Œä½†å®ƒå¯ä»¥ç”¨äºä»»ä½•å…¼å®¹ OIDC çš„è®¤è¯æœåŠ¡å™¨ã€‚

#### CLI ç‰¹æ€§

- **è‡ªåŠ¨è®¤è¯**: CLI ä¼šè‡ªåŠ¨ä½¿ç”¨å®¢æˆ·ç«¯å‡­è¯ä»è®¤è¯æœåŠ¡å™¨è·å–è®¿é—®ä»¤ç‰Œ
- **ä»¤ç‰Œç¼“å­˜**: è®¿é—®ä»¤ç‰Œä¼šç¼“å­˜åœ¨å†…å­˜ä¸­ï¼Œé¿å…é‡å¤è®¤è¯
- **è¿›åº¦æ˜¾ç¤º**: ä¸‹è½½å¤§æ–‡ä»¶æ—¶æ˜¾ç¤ºè¿›åº¦æ¡
- **é”™è¯¯å¤„ç†**: å‹å¥½çš„é”™è¯¯æç¤ºå’ŒçŠ¶æ€ç 

## ä½¿ç”¨ Makefileï¼ˆæ¨èï¼‰

é¡¹ç›®æä¾›äº† Makefile æ¥ç®€åŒ–å¸¸ç”¨æ“ä½œï¼š

```bash
# æŸ¥çœ‹æ‰€æœ‰å¯ç”¨å‘½ä»¤
make help

# å®‰è£…ä¾èµ–
make install

# å®‰è£…å¼€å‘ä¾èµ–
make install-dev

# è¿è¡Œå®Œæ•´ pipeline
make run

# å•ç‹¬è¿è¡Œå„ä¸ªæ¨¡å—
make train
make evaluate
make predict

# è¿è¡Œæµ‹è¯•
make test              # è¿è¡Œæ‰€æœ‰æµ‹è¯•
make test-unit         # è¿è¡Œå•å…ƒæµ‹è¯•
make test-integration  # è¿è¡Œé›†æˆæµ‹è¯•
make test-data         # è¿è¡Œæ•°æ®ç›¸å…³æµ‹è¯•
make test-device       # è¿è¡Œè®¾å¤‡ç›¸å…³æµ‹è¯•
make test-network      # è¿è¡Œç½‘ç»œç›¸å…³æµ‹è¯•
make test-metrics      # è¿è¡ŒæŒ‡æ ‡ç›¸å…³æµ‹è¯•
make test-coverage     # è¿è¡Œæµ‹è¯•å¹¶ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š

# ä»£ç è´¨é‡
make format    # æ ¼å¼åŒ–ä»£ç 
make lint      # ä»£ç æ£€æŸ¥
make test      # è¿è¡Œæµ‹è¯•

# è®¾å¤‡ç®¡ç†
make check-device   # æ£€æŸ¥è®¾å¤‡ä¿¡æ¯
make test-device    # æµ‹è¯•è®¾å¤‡åŠŸèƒ½

# æ¸…ç†ç¼“å­˜
make clean

# å¯åŠ¨ MLflow UI
make mlflow-ui
```

## æŠ€æœ¯æ ˆ

- **æ·±åº¦å­¦ä¹ **: PyTorch, Transformers
- **å®éªŒç®¡ç†**: MLflow
- **æ•°æ®å¤„ç†**: Pandas, NumPy
- **è¯„ä¼°æŒ‡æ ‡**: Scikit-learn
- **æ¨¡å‹**: huawei-noah/TinyBERT_General_4L_312D (å¯æ›¿æ¢ä¸ºå…¶ä»–é¢„è®­ç»ƒæ¨¡å‹)

## æ¨¡å‹æ¶æ„

- **è¾“å…¥**: é—®é¢˜ + [SEP] + æ¨ç†æ­¥éª¤
- **æ¨¡å‹**: huawei-noah/TinyBERT_General_4L_312D + åˆ†ç±»å¤´
- **è¾“å‡º**: äºŒåˆ†ç±» (æœ‰é”™è¯¯/æ— é”™è¯¯)
- **è¯„ä¼°æŒ‡æ ‡**: Accuracy, F1, Precision, Recall

## æ‰©å±•æ€§

### æ”¯æŒæ–°çš„æ¨¡å‹
åœ¨ `src/models/text_classifier.py` ä¸­æ·»åŠ æ–°çš„æ¨¡å‹ç±»ã€‚

### æ”¯æŒæ–°çš„æ•°æ®é›†æ ¼å¼
åœ¨ `src/data/loader.py` ä¸­æ·»åŠ æ–°çš„æ•°æ®åŠ è½½å‡½æ•°ã€‚

### æ”¯æŒæ–°çš„è¯„ä¼°æŒ‡æ ‡
åœ¨è®­ç»ƒå’Œè¯„ä¼°è„šæœ¬çš„ `compute_metrics` å‡½æ•°ä¸­æ·»åŠ æ–°æŒ‡æ ‡ã€‚

## å‚æ•°è¯´æ˜

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--data_path` | `data/0312_training_fast_slow_thinking.jsonl` | æ•°æ®æ–‡ä»¶è·¯å¾„ |
| `--model_name` | `huawei-noah/TinyBERT_General_4L_312D` | é¢„è®­ç»ƒæ¨¡å‹åç§° |
| `--epochs` | `3` | è®­ç»ƒè½®æ•° |
| `--batch_size` | `8` | æ‰¹æ¬¡å¤§å° |
| `--max_length` | `512` | æœ€å¤§åºåˆ—é•¿åº¦ |
| `--learning_rate` | `2e-5` | å­¦ä¹ ç‡ |
| `--test_size` | `0.2` | æµ‹è¯•é›†æ¯”ä¾‹ |
| `--device` | `auto` | è®¾å¤‡é€‰æ‹© (auto/cpu/cuda/mps) |

## è®¾å¤‡é…ç½®

### æ£€æŸ¥è®¾å¤‡
```bash
# ä½¿ç”¨ Makefile
make check-device

# æˆ–ç›´æ¥è¿è¡Œ
uv run python check_device.py
```

### è®¾å¤‡é€‰æ‹©
- `--device auto`: è‡ªåŠ¨é€‰æ‹©æœ€ä½³è®¾å¤‡ï¼ˆæ¨èï¼‰
- `--device cpu`: å¼ºåˆ¶ä½¿ç”¨ CPU
- `--device cuda`: ä½¿ç”¨ NVIDIA GPU
- `--device mps`: ä½¿ç”¨ Apple Silicon GPU (MPS)

## æ³¨æ„äº‹é¡¹

1. ç¡®ä¿æœ‰è¶³å¤Ÿçš„ GPU å†…å­˜ï¼ˆå»ºè®® 8GB+ï¼‰
2. å¤§æ•°æ®é›†è®­ç»ƒæ—¶é—´è¾ƒé•¿ï¼Œå»ºè®®ä½¿ç”¨ GPU
3. MLflow ä¼šè‡ªåŠ¨è®°å½•æ‰€æœ‰å®éªŒå‚æ•°å’ŒæŒ‡æ ‡
4. æ¨¡å‹ä¼šè‡ªåŠ¨ä¿å­˜åˆ° `outputs/` ç›®å½•
5. **é‡è¦**: ç¡®ä¿æ¿€æ´»è™šæ‹Ÿç¯å¢ƒåå†è¿è¡Œ Python è„šæœ¬

## æ•…éšœæ’é™¤

å¦‚æœé‡åˆ°é—®é¢˜ï¼Œè¯·æŸ¥çœ‹ [æ•…éšœæ’é™¤æŒ‡å—](TROUBLESHOOTING.md) è·å–è¯¦ç»†è§£å†³æ–¹æ¡ˆã€‚
