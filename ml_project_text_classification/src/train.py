import os
import mlflow
import mlflow.transformers
import mlflow.models
import pandas as pd
from transformers import TrainingArguments, Trainer
from src.data.loader import load_llm_router_data
from src.data.dataset import create_datasets_from_dataframes
from src.models.text_classifier import TextClassifier
from src.utils.device import get_device, print_device_info
from src.utils.network import check_network_connection, setup_hf_environment
from src.utils.metrics import compute_classification_metrics
import argparse

def main(args):
    # è®¾ç½®ç¯å¢ƒ
    setup_hf_environment()
    
    # æ£€æŸ¥ç½‘ç»œè¿æ¥
    if not check_network_connection():
        raise Exception("âŒ æ— æ³•è¿æ¥åˆ°ä»»ä½• HuggingFace é•œåƒç«™ç‚¹ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
    
    # è®¾ç½®è®¾å¤‡
    device = get_device(args.device)
    print_device_info(device)
    
    mlflow.set_experiment(args.experiment_name)
    with mlflow.start_run(run_name=f"train-{args.model_name}-{args.epochs}epochs"):
        print("ğŸ“Š åŠ è½½ LLM Router æ•°æ®...")
        
        # åŠ è½½æ•°æ®
        if args.test_path:
            train_df, test_df = load_llm_router_data(args.data_path, args.test_path)
        else:
            train_df, test_df = load_llm_router_data(args.data_path)
        
        num_labels = 2  # äºŒåˆ†ç±»ï¼š0 vs 1
        
        print(f"ğŸ“ˆ è®­ç»ƒé›†å¤§å°: {len(train_df)}")
        print(f"ğŸ“‰ æµ‹è¯•é›†å¤§å°: {len(test_df)}")
        
        print(f"ğŸ¤– ä» HuggingFace é•œåƒåŠ è½½æ¨¡å‹ {args.model_name}...")
        model = TextClassifier(args.model_name, num_labels, device=device)
        tokenizer = model.get_tokenizer()
        
        print("ğŸ”§ å¤„ç†æ•°æ®...")
        train_dataset, test_dataset = create_datasets_from_dataframes(
            train_df=train_df,
            test_df=test_df,
            tokenizer=tokenizer,
            max_length=args.max_length
        )
        
        print("âš™ï¸  è®¾ç½®è®­ç»ƒå‚æ•°...")
        training_args = TrainingArguments(
            output_dir=args.output_dir,
            num_train_epochs=args.epochs,
            per_device_train_batch_size=args.batch_size,
            per_device_eval_batch_size=args.batch_size,
            eval_strategy="epoch",  # æ–°ç‰ˆæœ¬å‚æ•°å
            save_strategy="epoch",
            logging_dir=os.path.join(args.output_dir, 'logs'),
            logging_steps=10,
            load_best_model_at_end=True,
            metric_for_best_model="f1",
            greater_is_better=True,
            warmup_steps=args.warmup_steps,
            learning_rate=args.learning_rate,
            weight_decay=args.weight_decay,
            no_cuda=(device.type == 'cpu'),  # å¦‚æœä½¿ç”¨CPUï¼Œç¦ç”¨CUDA
        )
        
        trainer = Trainer(
            model=model.get_model(),
            args=training_args,
            train_dataset=train_dataset,
            eval_dataset=test_dataset,
            compute_metrics=compute_classification_metrics,
        )
        
        mlflow.log_params(vars(args))
        
        # æ·»åŠ æœ‰ç”¨çš„æ ‡ç­¾
        mlflow.set_tag("model_type", "transformer")
        mlflow.set_tag("task", "text-classification")
        mlflow.set_tag("framework", "transformers")
        mlflow.set_tag("num_labels", num_labels)
        
        print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
        trainer.train()
        print("ğŸ“Š è®­ç»ƒå®Œæˆï¼Œå¼€å§‹è¯„ä¼°...")
        metrics = trainer.evaluate()
        mlflow.log_metrics(metrics)
        
        # ä¿å­˜æ¨¡å‹åˆ°æœ¬åœ°ç›®å½•
        model_save_path = os.path.join(args.output_dir, "final_model")
        trainer.save_model(model_save_path)
        tokenizer.save_pretrained(model_save_path)
        
        # ä½¿ç”¨MLFlow transformersè®°å½•æ¨¡å‹ï¼Œç¡®ä¿UIå…¼å®¹æ€§
        mlflow.transformers.log_model(
            transformers_model={
                "model": model.get_model(),
                "tokenizer": tokenizer
            },
            artifact_path="model",
            task="text-classification",
            registered_model_name=f"{args.experiment_name}-model",
            input_example="a simple or complex question",
            signature=mlflow.models.infer_signature(
                model_input="a simple or complex question",
                model_output=[{"label": "LABEL_1", "score": 0.8}]
            )
        )
        
        # è®°å½•æ¨¡å‹è·¯å¾„åˆ°MLflowä½œä¸ºå¤‡ç”¨
        mlflow.log_artifact(model_save_path, "model_files")
        
        print("âœ… è®­ç»ƒå®Œæˆï¼æœ€ç»ˆæŒ‡æ ‡:", metrics)
        print(f"ğŸ“ æ¨¡å‹å·²ä¿å­˜åˆ°: {model_save_path}")
        print(f"ğŸ”— MLFlowæ¨¡å‹å·²æ³¨å†Œ: {args.experiment_name}-model")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--data_path', type=str, default='data/llm_router_dataset-synth/train.jsonl')
    parser.add_argument('--model_name', type=str, default='distilbert-base-uncased')
    parser.add_argument('--output_dir', type=str, default='./outputs')
    parser.add_argument('--epochs', type=int, default=3)
    parser.add_argument('--batch_size', type=int, default=8)
    parser.add_argument('--max_length', type=int, default=512)

    parser.add_argument('--experiment_name', type=str, default='llm-router-classification')
    parser.add_argument('--warmup_steps', type=int, default=500)
    parser.add_argument('--learning_rate', type=float, default=2e-5)
    parser.add_argument('--weight_decay', type=float, default=0.01)
    parser.add_argument('--device', type=str, default='auto', 
                       choices=['auto', 'cpu', 'cuda', 'mps'],
                       help='è®¾å¤‡é€‰æ‹©: auto(è‡ªåŠ¨), cpu, cuda, mps')
    parser.add_argument('--test_path', type=str, default=None,
                       help='æµ‹è¯•é›†æ–‡ä»¶è·¯å¾„')
    args = parser.parse_args()
    main(args)


