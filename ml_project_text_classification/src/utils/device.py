"""
è®¾å¤‡ç®¡ç†å·¥å…·å‡½æ•°
"""

import torch
from typing import Union, Optional

def get_device(device: str = 'auto') -> torch.device:
    """
    èŽ·å–è®¾å¤‡å¯¹è±¡
    
    Args:
        device: è®¾å¤‡é€‰æ‹© ('auto', 'cpu', 'cuda', 'mps') æˆ– None
    
    Returns:
        torch.device: è®¾å¤‡å¯¹è±¡
    """
    if device is None or device == 'auto':
        if torch.cuda.is_available():
            return torch.device('cuda')
        elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            return torch.device('mps')
        else:
            return torch.device('cpu')
    else:
        return torch.device(device)

def print_device_info(device: torch.device) -> None:
    """
    æ‰“å°è®¾å¤‡ä¿¡æ¯
    
    Args:
        device: è®¾å¤‡å¯¹è±¡
    """
    print(f"ðŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")
    
    if device.type == 'cuda':
        print(f"ðŸŽ® GPU: {torch.cuda.get_device_name(0)}")
        print(f"ðŸ’¾ GPU å†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    elif device.type == 'mps':
        print("ðŸŽ ä½¿ç”¨ Apple Silicon GPU (MPS)")

def get_device_recommendations() -> dict:
    """
    èŽ·å–è®¾å¤‡æŽ¨èé…ç½®
    
    Returns:
        dict: è®¾å¤‡æŽ¨èé…ç½®
    """
    if torch.cuda.is_available():
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        if gpu_memory >= 8:
            return {
                'batch_size': '16-32',
                'max_length': '512-1024',
                'description': 'NVIDIA GPU 8GB+'
            }
        elif gpu_memory >= 4:
            return {
                'batch_size': '8-16',
                'max_length': '256-512',
                'description': 'NVIDIA GPU 4-8GB'
            }
        else:
            return {
                'batch_size': '4-8',
                'max_length': '128-256',
                'description': 'NVIDIA GPU <4GB'
            }
    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        return {
            'batch_size': '8-16',
            'max_length': '256-512',
            'description': 'Apple Silicon GPU'
        }
    else:
        return {
            'batch_size': '2-4',
            'max_length': '128-256',
            'description': 'CPU'
        }
