#!/bin/bash

# LLM Router æ–‡æœ¬åˆ†ç±»é¡¹ç›®è®­ç»ƒå’Œè¯„ä¼°è„šæœ¬

echo "=== LLM Router æ–‡æœ¬åˆ†ç±» Pipeline ==="

# è®¾ç½®ç¯å¢ƒå˜é‡ - ä½¿ç”¨ HF-Mirror
export PYTHONPATH="${PYTHONPATH}:$(pwd)"
export HF_HUB_OFFLINE=0  # å¼ºåˆ¶åœ¨çº¿æ¨¡å¼
export TRANSFORMERS_CACHE=""  # ç¦ç”¨ç¼“å­˜
export HF_HOME=""  # ç¦ç”¨ç¼“å­˜
export HF_DATASETS_CACHE=""  # ç¦ç”¨æ•°æ®é›†ç¼“å­˜
export HF_ENDPOINT="https://hf-mirror.com"  # ä½¿ç”¨ HF-Mirror

# åˆ›å»ºè¾“å‡ºç›®å½•
mkdir -p outputs
mkdir -p mlruns

# æ£€æŸ¥ç½‘ç»œè¿æ¥ - æµ‹è¯•å¤šä¸ªé•œåƒç«™ç‚¹
echo "æ£€æŸ¥ç½‘ç»œè¿æ¥..."
mirror_urls=("https://hf-mirror.com" "https://huggingface.co")
network_ok=false

for url in "${mirror_urls[@]}"; do
    echo "æµ‹è¯•è¿æ¥: $url"
    if curl -s --connect-timeout 10 "$url" > /dev/null; then
        echo "âœ… å¯ä»¥è¿æ¥åˆ°: $url"
        export HF_ENDPOINT="$url"
        network_ok=true
        break
    else
        echo "âŒ æ— æ³•è¿æ¥åˆ°: $url"
    fi
done

if [ "$network_ok" = false ]; then
    echo "âŒ æ— æ³•è¿æ¥åˆ°ä»»ä½• HuggingFace é•œåƒç«™ç‚¹ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥"
    exit 1
fi

# æ£€æŸ¥ä¾èµ–
echo "æ£€æŸ¥ä¾èµ–åŒ…..."
python -c "import transformers, mlflow, torch; print('âœ… æ‰€æœ‰ä¾èµ–åŒ…å·²å®‰è£…')" || {
    echo "âŒ ç¼ºå°‘ä¾èµ–åŒ…ï¼Œæ­£åœ¨å®‰è£…..."
    if command -v uv &> /dev/null; then
        echo "ä½¿ç”¨ uv å®‰è£…ä¾èµ–..."
        uv sync
    else
        echo "ä½¿ç”¨ pip å®‰è£…ä¾èµ–..."
        pip install -r requirements.txt
    fi
}

# æ£€æŸ¥æ•°æ®æ–‡ä»¶
if [ ! -f "src/data/llm_router_dataset-synth/train.jsonl" ]; then
    echo "âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°è®­ç»ƒæ•°æ®æ–‡ä»¶ src/data/llm_router_dataset-synth/train.jsonl"
    exit 1
fi

if [ ! -f "src/data/llm_router_dataset-synth/test.jsonl" ]; then
    echo "âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æµ‹è¯•æ•°æ®æ–‡ä»¶ src/data/llm_router_dataset-synth/test.jsonl"
    exit 1
fi

# è®­ç»ƒæ¨¡å‹
echo "ğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹..."
python src/train.py \
    --data_path src/data/llm_router_dataset-synth/train.jsonl \
    --test_path src/data/llm_router_dataset-synth/test.jsonl \
    --model_name distilbert-base-uncased \
    --output_dir ./outputs \
    --epochs 1 \
    --batch_size 32 \
    --max_length 512 \
    --experiment_name llm-router-classification \
    --warmup_steps 500 \
    --learning_rate 2e-5 \
    --weight_decay 0.01 \
    --device auto

if [ $? -eq 0 ]; then
    echo "âœ… è®­ç»ƒå®Œæˆï¼"
else
    echo "âŒ è®­ç»ƒå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯"
    exit 1
fi

# è¯„ä¼°æ¨¡å‹
echo "ğŸ“Š å¼€å§‹è¯„ä¼°æ¨¡å‹..."
python src/evaluate.py \
    --data_path src/data/llm_router_dataset-synth/train.jsonl \
    --test_path src/data/llm_router_dataset-synth/test.jsonl \
    --model_name distilbert-base-uncased \
    --max_length 512 \
    --experiment_name llm-router-classification \
    --device auto

if [ $? -eq 0 ]; then
    echo "âœ… è¯„ä¼°å®Œæˆï¼"
else
    echo "âŒ è¯„ä¼°å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯"
fi

# æ£€æŸ¥æ˜¯å¦æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹
if [ -d "./outputs" ] && [ "$(ls -A ./outputs)" ]; then
    echo "ğŸ”® å¼€å§‹æ‰¹é‡é¢„æµ‹..."
    python src/predict.py \
        --model_path ./outputs \
        --data_path src/data/llm_router_dataset-synth/test.jsonl \
        --output_path predictions.jsonl \
        --max_length 512 \
        --device auto
else
    echo "âš ï¸  è­¦å‘Šï¼šæ²¡æœ‰æ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œè·³è¿‡é¢„æµ‹æ­¥éª¤"
fi

echo "ğŸ‰ Pipeline å®Œæˆï¼"
echo "ğŸ“ å®éªŒæ—¥å¿—ä½ç½®: ./mlruns/"
echo "ğŸ“ æ¨¡å‹è¾“å‡ºä½ç½®: ./outputs/"
echo "ğŸŒ æŸ¥çœ‹ MLflow UI: mlflow ui"
